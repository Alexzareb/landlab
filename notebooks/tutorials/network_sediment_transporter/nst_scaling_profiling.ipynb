{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://landlab.github.io\"><img style=\"float: left\" src=\"../../landlab_header.png\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling and Scaling Analysis of the NetworkSedimentTransporter\n",
    "\n",
    "Part 1: Do some stuff to give us generic, variable sized grids and parcels. \n",
    "Part 2: Do some profiling. \n",
    "Part 2: Do some scaling analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from landlab.components import FlowDirectorSteepest, NetworkSedimentTransporter\n",
    "from landlab.data_record import DataRecord\n",
    "from landlab.grid.network import NetworkModelGrid\n",
    "from landlab.plot import graph\n",
    "\n",
    "import cProfile\n",
    "import pstats\n",
    "from pstats import SortKey\n",
    "import io\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Variably-sized grids and parcels\n",
    "\n",
    "### Part 1a: Grids\n",
    "\n",
    "First, we need the ability to create different sizes of grids. \n",
    "\n",
    "A simple approach is to create a generic grid in which each node has two recievers. Lets start by writing a function that creates the x and y node coordinates and the linking structure for a given number of layers.   \n",
    "\n",
    "I haven't tried to optimize this at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_xy_and_links(n_layers, x0=0., y0=0., xperc=0.9, dy=1.):\n",
    "    assert xperc<1.0\n",
    "    nodes_per_layer = np.power(2, np.arange(n_layers+1))\n",
    "    nnodes = np.sum(nodes_per_layer)   \n",
    "    x_of_node=[x0]\n",
    "    y_of_node=[y0]\n",
    "    nodes_at_link = []\n",
    "    id_start_layer = 0\n",
    "    for nl in np.arange(1, n_layers+1):\n",
    "        nodes_last_layer = np.power(2, nl-1)\n",
    "        nodes_this_layer = np.power(2, nl)              \n",
    "        dx = xperc * (dy)*(0.5**(nl-1))\n",
    "        for ni in range(nodes_last_layer):\n",
    "            head_id = id_start_layer+ni            \n",
    "            tail_id = len(x_of_node)           \n",
    "            x = x_of_node[head_id]\n",
    "            y = y_of_node[head_id]            \n",
    "            x_of_node.extend([x-dx, x+dx])\n",
    "            y_of_node.extend([y+dy, y+dy])            \n",
    "            nodes_at_link.extend([(head_id, tail_id), (head_id, tail_id +1)])   \n",
    "        id_start_layer = len(x_of_node) - nodes_this_layer\n",
    "    return x_of_node, y_of_node, nodes_at_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets demonstrate the different sorts of grids we get with different numbers of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_layers = [1, 3, 5, 7, 9]\n",
    "\n",
    "nodes = []\n",
    "for i, n_layers in enumerate(example_layers):\n",
    "    x_of_node, y_of_node, nodes_at_link = create_node_xy_and_links(n_layers)\n",
    "    grid = NetworkModelGrid((y_of_node, x_of_node), nodes_at_link)\n",
    "\n",
    "    graph.plot_graph(grid, at=\"node,link\", with_id=False)\n",
    "    nodes.append(grid.number_of_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(example_layers, nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b: Generic grid.\n",
    "\n",
    "The grid needs some additional fields added to it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nmg_and_fd(n_layers):\n",
    "    x_of_node, y_of_node, nodes_at_link = create_node_xy_and_links(n_layers)\n",
    "    grid = NetworkModelGrid((y_of_node, x_of_node), nodes_at_link)\n",
    "\n",
    "    _ = grid.add_field(\"topographic__elevation\", grid.y_of_node.copy(), at=\"node\")\n",
    "    _ = grid.add_field(\"bedrock__elevation\", grid.y_of_node.copy(), at=\"node\")\n",
    "\n",
    "    _ = grid.add_field(\"reach_length\", 200.*np.ones(grid.number_of_links), at=\"link\")  # m\n",
    "    _ = grid.add_field(\"channel_width\", 1.*np.ones(grid.number_of_links), at=\"link\")  # m\n",
    "    \n",
    "    fd = FlowDirectorSteepest(grid)\n",
    "    fd.run_one_step()\n",
    "    return grid, fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c: Generic sets of parcels\n",
    "A real application would likley use 50k+ parcels (b/c you want the full gsd) and 100-500 links in the network. \n",
    "You typically want at least 100 parcels per link. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parcels(grid, parcels_per_link=5):\n",
    "\n",
    "    # element_id is the link on which the parcel begins. \n",
    "    element_id = np.repeat(np.arange(grid.number_of_links), parcels_per_link)\n",
    "    element_id = np.expand_dims(element_id, axis=1)\n",
    "\n",
    "    volume = 1*np.ones(np.shape(element_id))  # (m3)\n",
    "    active_layer = np.ones(np.shape(element_id)) # 1= active, 0 = inactive\n",
    "    density = 2650 * np.ones(np.size(element_id))  # (kg/m3)\n",
    "    abrasion_rate = 0 * np.ones(np.size(element_id)) # (mass loss /m)\n",
    "\n",
    "    # Lognormal GSD\n",
    "    medianD = 0.085 # m\n",
    "    mu = np.log(medianD)\n",
    "    sigma = np.log(2) #assume that D84 = sigma*D50\n",
    "    np.random.seed(0)\n",
    "    D = np.random.lognormal(\n",
    "        mu,\n",
    "        sigma,\n",
    "        np.shape(element_id)\n",
    "    )  # (m) the diameter of grains in each parcel\n",
    "\n",
    "    time_arrival_in_link = np.random.rand(np.size(element_id), 1) \n",
    "    location_in_link = np.random.rand(np.size(element_id), 1) \n",
    "\n",
    "    variables = {\n",
    "        \"abrasion_rate\": ([\"item_id\"], abrasion_rate),\n",
    "        \"density\": ([\"item_id\"], density),\n",
    "        \"time_arrival_in_link\": ([\"item_id\", \"time\"], time_arrival_in_link),\n",
    "        \"active_layer\": ([\"item_id\", \"time\"], active_layer),\n",
    "        \"location_in_link\": ([\"item_id\", \"time\"], location_in_link),\n",
    "        \"D\": ([\"item_id\", \"time\"], D),\n",
    "        \"volume\": ([\"item_id\", \"time\"], volume)\n",
    "    }\n",
    "\n",
    "\n",
    "    items = {\"grid_element\": \"link\", \"element_id\": element_id}\n",
    "\n",
    "    _OUT_OF_NETWORK = NetworkModelGrid.BAD_INDEX - 1\n",
    "\n",
    "    parcels = DataRecord(\n",
    "        grid,\n",
    "        items=items,\n",
    "        time=[0.0],\n",
    "        data_vars=variables,\n",
    "        dummy_elements={\"link\": [_OUT_OF_NETWORK]},\n",
    "    )\n",
    "\n",
    "    return parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all(nlayer=3, parcels_per_link=100, timesteps=10):\n",
    "\n",
    "    grid, fd = create_nmg_and_fd(nlayer)\n",
    "\n",
    "    parcels = create_parcels(grid, parcels_per_link=parcels_per_link)\n",
    "\n",
    "    dt = 60 * 60 * 24 *12 # length of timestep (seconds) \n",
    "    flow_depth =  2.5 * np.ones([timesteps + 1, grid.number_of_links])\n",
    "    \n",
    "    return grid, fd, parcels, flow_depth, dt, timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, fd, parcels, flow_depth, dt, timesteps = create_all(nlayer=4, parcels_per_link=50, timesteps=10)\n",
    "\n",
    "nst = NetworkSedimentTransporter(    \n",
    "    grid,\n",
    "    parcels,\n",
    "    fd,\n",
    "    flow_depth,\n",
    "    bed_porosity=0.3,\n",
    "    g=9.81,\n",
    "    fluid_density=1000,\n",
    "    transport_method=\"WilcockCrowe\",\n",
    ")\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "for t in range(0, (timesteps * dt), dt):\n",
    "    nst.run_one_step(dt)\n",
    "pr.disable()\n",
    "s = io.StringIO()\n",
    "sortby = SortKey.CUMULATIVE\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "ps.print_stats()\n",
    "#print(s.getvalue())\n",
    "\n",
    "with open(\"profile.txt\", \"w\") as f:\n",
    "    f.write(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_code(nlayer=3, parcels_per_link=100, timesteps=10):\n",
    "\n",
    "    grid, fd = create_nmg_and_fd(nlayer)\n",
    "\n",
    "    parcels = create_parcels(grid, parcels_per_link=parcels_per_link)\n",
    "\n",
    "    dt = 60 * 60 * 24 *12 # length of timestep (seconds) \n",
    "    flow_depth =  2.5 * np.ones([timesteps + 1, grid.number_of_links])\n",
    "\n",
    "    init_start = time.time()\n",
    "    nst = NetworkSedimentTransporter(    \n",
    "        grid,\n",
    "        parcels,\n",
    "        fd,\n",
    "        flow_depth,\n",
    "        bed_porosity=0.3,\n",
    "        g=9.81,\n",
    "        fluid_density=1000,\n",
    "        transport_method=\"WilcockCrowe\",\n",
    "    )\n",
    "    init_duration = time.time() - init_start\n",
    "\n",
    "    partition = []\n",
    "    move_parcel = []\n",
    "    \n",
    "    for t in range(timesteps):\n",
    "        nst._time += dt\n",
    "\n",
    "        nst._time_idx += 1\n",
    "        nst._create_new_parcel_time()\n",
    "\n",
    "        if nst._this_timesteps_parcels.any():\n",
    "            \n",
    "            partition_start = time.time()\n",
    "            nst._partition_active_and_storage_layers()\n",
    "            partition.append(time.time()-partition_start)\n",
    "            \n",
    "            nst._adjust_node_elevation()\n",
    "            nst._update_channel_slopes()\n",
    "            nst._update_transport_time()\n",
    "            \n",
    "            move_start = time.time()\n",
    "            nst._move_parcel_downstream(dt)\n",
    "            move_parcel.append(time.time()-move_start)\n",
    "            \n",
    "        else:\n",
    "            msg = \"No more parcels on grid\"\n",
    "            raise RuntimeError(msg)\n",
    "\n",
    "    return (grid.number_of_nodes, parcels_per_link, timesteps), init_duration, partition, move_parcel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(nn, ppl, ts), init, part, move = profile_code(\n",
    "    nlayer=3, \n",
    "    parcels_per_link=100, \n",
    "    timesteps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {}\n",
    "for i in range(2, 7):\n",
    "    for j in [10, 20, 50, 100, 200, 500, 1000, 2000]:\n",
    "        (nn, ppl, ts), init, part, move = profile_code(\n",
    "            nlayer=i, \n",
    "            parcels_per_link=j, \n",
    "            timesteps=0)\n",
    "        out[(nn, ppl)] = {\"init\": init}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(out)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nst._time += dt\n",
    "nst._time_idx += 1\n",
    "nst._create_new_parcel_time()\n",
    "\n",
    "nst._partition_active_and_storage_layers()\n",
    "nst._adjust_node_elevation()\n",
    "nst._update_channel_slopes()\n",
    "nst._update_transport_time()\n",
    "\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "nst._move_parcel_downstream(dt)\n",
    "pr.disable()\n",
    "s = io.StringIO()\n",
    "sortby = SortKey.CUMULATIVE\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "ps.print_stats()\n",
    "#print(s.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"profile_move_downstream.txt\", \"w\") as f:\n",
    "    f.write(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.number_of_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels._dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
